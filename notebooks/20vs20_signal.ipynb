{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 20 vs 20 signal processing\n",
    "\n",
    "## 2 ways to process signal\n",
    "* Based on exact tags count using fragment size\n",
    "    UNIQUE_BAM -> PILEUP_BED -> TAGS -> intersect with given regions bed and compute intersection\n",
    "* Based on bigwigs\n",
    "    UNIQUE_BAM -> BIGWIG -> bigWigAverageOverBed\n",
    "    \n",
    "### Unique BAM -> TAGS\n",
    "```\n",
    "./gradlew integration:shadowJar && java -cp integration/build/libs/integration-dev.jar org.jetbrains.bio.experiments.histones.UniqueBamsExperiment Y20O20\n",
    "\n",
    "cd /mnt/stripe/bio/experiments/configs/Y20O20/unique\n",
    "for D in $(ls . | grep -v yaml); do \n",
    "    echo $(pwd)/$D; \n",
    "    bash /mnt/stripe/washu/parallel/tags_bigwig.sh /mnt/stripe/bio/genomes/hg19/hg19.chrom.sizes 150 $(pwd)/$D; \n",
    "done\n",
    "```\n",
    "\n",
    "## Interesting LOCI\n",
    "* Auto generated `/mnt/stripe/bio/experiments/loci_of_interest/`\n",
    "* All merged `/mnt/stripe/bio/raw-data/aging/loci_of_interest/`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare BigWigs\n",
    "```\n",
    "# Prepare data\n",
    "for M in H3K27ac H3K27me3 H3K36me3 H3K4me1 H3K4me3; do \n",
    "    echo $M; \n",
    "    mkdir $M; \n",
    "    ls /mnt/stripe/bio/experiments/configs/Y20O20/unique_tags_bw/$M/*.bw | xargs -I {} ln -s {} $M/; \n",
    "    # In case we have input separated processed\n",
    "    # ls /mnt/stripe/bio/experiments/configs/Y20O20/unique_tags_bw/input/*.bw xargs -I {} ln -s {} $M/;\n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process signals and build PCA\n",
    "```\n",
    "export PYTHONPATH=\"/mnt/stripe/washu:$PYTHONPATH\"\n",
    "export WASHU_PARALLELISM=16\n",
    "DIR=$(pwd)\n",
    "for M in $(find . -maxdepth 1  -type d | grep '/' | sed 's#./##g'); do\n",
    "    echo \"Processing $M\"; \n",
    "    cd $DIR/$M\n",
    "    for F in $(find /mnt/stripe/bio/raw-data/aging/loci_of_interest/ -name \"*.bed\" | grep -vE 'repeats|other_pathway'); do \n",
    "        echo \"$M regions $F\"; \n",
    "        N=${F%%.bed}; \n",
    "        N=${N##*/}; \n",
    "        if [ ! -d $DIR/$M/$N ]; then\n",
    "            bash /mnt/stripe/washu/parallel/signals_bw.sh $DIR/$M $F $N /mnt/stripe/bio/genomes/hg19/hg19.chrom.sizes $PEAKS;\n",
    "        fi;\n",
    "    done;\n",
    "done | tee log.txt\n",
    "\n",
    "# Create report\n",
    "bash /mnt/stripe/washu/reports/signals_report.sh $(pwd) $(pwd)/report.tsv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup possible errors\n",
    "```\n",
    "DIR=$(pwd)\n",
    "for M in H3K27ac H3K27me3 H3K36me3 H3K4me1 H3K4me3; do \n",
    "    cd ${DIR}/$M; \n",
    "    echo $M; \n",
    "    for F in $(find . -maxdepth 1  -type d | grep '/' | sed 's#./##g'); do \n",
    "        PNGS=$(find $F -name \"*.png\"); \n",
    "        if [[ -z \"$PNGS\" ]]; then \n",
    "            echo \"$M $F\"; \n",
    "            rm -r $F; \n",
    "        fi; \n",
    "    done; \n",
    "done\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "from scipy.stats import mannwhitneyu\n",
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from scripts.util import *\n",
    "\n",
    "def stat_test(folder, m, test_name, test, alpha, min_pval):\n",
    "    folder = os.path.join(folder, m)\n",
    "    for signal_type in ['raw', 'rpm', 'rpkm', 'scores', 'scores_tmm']:\n",
    "        for f in glob.glob('{}/*/{}*weak_consensus*{}.tsv'.format(folder, m, signal_type)):\n",
    "            # Ignore ODS vs YDS here             \n",
    "            if re.match('.*DS.*', f):\n",
    "                continue\n",
    "            print('Processing', m, '@', re.sub('[^/]*/', '', f))\n",
    "            df = pd.read_csv(f, sep='\\t')\n",
    "            # Drop contigs\n",
    "            df = df.loc[[bool(re.match('chr[0-9XYM]+$', c)) for c in df['chr']]]\n",
    "            ods = [c for c in df.columns.values if is_od(c)]\n",
    "            yds = [c for c in df.columns.values if is_yd(c)]\n",
    "            pvals = np.array([test(row[ods], row[yds]) for _,row in df.iterrows()])\n",
    "            res = multipletests(pvals, alpha, \"fdr_bh\")\n",
    "            h0_rejects = res[0]\n",
    "            pvals_adj = res[1]\n",
    "            df['pval'] = pvals\n",
    "            df['pval_adj'] = pvals_adj\n",
    "            df['od_mean'] = df[ods].mean(axis=1).to_frame('od_mean')['od_mean']\n",
    "            df['yd_mean'] = df[yds].mean(axis=1).to_frame('yd_mean')['yd_mean']\n",
    "            df['logfc'] = np.log(df['od_mean'] / df['yd_mean'])\n",
    "            # Sort by pvalues \n",
    "            dfp = df.loc[pvals.argsort()[:5]]\n",
    "            dfp = df.loc[df['pval'] < min_pval]\n",
    "            print(\"Locations: {}; FDR={}: {}; pvals < {}: {}\".format(\n",
    "                    len(df), alpha, sum(h0_rejects), min_pval, len(dfp)))\n",
    "            # Display top 5 smallest pvalues\n",
    "            if (len(dfp) > 0):\n",
    "                print(dfp.loc[:5][['chr', 'start', 'end', 'yd_mean', 'od_mean', 'logfc', 'pval']])\n",
    "            # Save result to file            \n",
    "            if sum(h0_rejects) > 0:\n",
    "                testf = re.sub('\\.tsv', '_{}.tsv'.format(test_name), f)\n",
    "                df.loc[h0_rejects][['chr', 'start', 'end', 'yd_mean', 'od_mean', 'logfc', 'pval', 'pval_adj']]\\\n",
    "                .to_csv(testf, sep='\\t', index=None, header=True)\n",
    "                print('Saved {} regions to {}'.format(sum(h0_rejects), testf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MannWhitney U test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def mann_whitney(x, y):\n",
    "    try:\n",
    "        # Mann-Whitney U test     \n",
    "        return mannwhitneyu(x, y).pvalue\n",
    "    except ValueError:\n",
    "        return 1.0\n",
    "\n",
    "for m in ['H3K27ac', 'H3K27me3', 'H3K36me3', 'H3K4me1', 'H3K4me3']:\n",
    "    stat_test('/mnt/stripe/bio/experiments/signal_loci_of_interest_auto', m, 'mann_whitney', mann_whitney, 0.05, 1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# T-Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import scipy\n",
    "def ttest(x, y):\n",
    "    try:\n",
    "        return scipy.stats.ttest_ind(x, y).pvalue\n",
    "    except ValueError:\n",
    "        return 1.0\n",
    "\n",
    "for m in ['H3K27ac', 'H3K27me3', 'H3K36me3', 'H3K4me1', 'H3K4me3']:\n",
    "    stat_test('/mnt/stripe/bio/experiments/signal_loci_of_interest_auto', m, 'ttest', ttest, 0.05, 1e-4)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
