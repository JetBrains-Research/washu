{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:29:56.461918Z",
     "start_time": "2018-02-13T11:29:56.448157Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from downstream.signals.signal_r2_permutation_test import process, collect_paths\n",
    "from downstream.signals.signals_util import extract_normalization, extract_datatype\n",
    "import downstream.bed_metrics as bm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:22.202076Z",
     "start_time": "2018-02-12T14:12:22.197706Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# simulations = 6\n",
    "simulations = 100001\n",
    "threads = 8\n",
    "clear_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:22.220739Z",
     "start_time": "2018-02-12T14:12:22.215916Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def walk_folders(path):\n",
    "    yield path\n",
    "    for f in path.iterdir():\n",
    "        if f.is_dir():\n",
    "            yield from walk_folders(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histone modifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:22.263566Z",
     "start_time": "2018-02-12T14:12:22.235993Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datatype_loci = defaultdict(list)\n",
    "datatype_loci[\"meth\"] = [\n",
    "    \"ucsc_cpgIslandExt.hg19\", \n",
    "    \"cpg_minavcov10_complex_4outliers.narrow.adjusted.regions.filtered\",\n",
    "    \"washu_german_rrbs_filtered_dmrs_all_10.hg19\"\n",
    "]\n",
    "datatype_loci[\"H3K36me3\"] = [\"coding_transcript\", \"noncoding_transcript\"]\n",
    "\n",
    "hist_to_chromhmm_states = {\n",
    "    \"H3K4me1\": [\"8_EnhG2\", \"9_EnhA1\"],\n",
    "    \"H3K4me3\": [\"1_TssA\", \"2_TssFlnk\"],\n",
    "    \"H3K27ac\": [\"1_TssA\", \"3_TssFlnkU\"],\n",
    "    \"H3K36me3\": [\"5_Tx\", \"7_EnhG1\", \"8_EnhG2\"],\n",
    "    \"H3K27me3\": [\"14_TssBiv\", \"15_EnhBiv\",\"16_ReprPC\"],\n",
    "}\n",
    "for hist, states in hist_to_chromhmm_states.items():\n",
    "    for s in states:\n",
    "        for vers in [\"encsr511wof\", \"encsr907lcd\"]:\n",
    "            datatype_loci[hist].append(\"cd14_{}_chromhmm18.hg19.{}\".format(vers, s))\n",
    "        \n",
    "for dt in [\"H3K4me1\", \"H3K4me3\", \"H3K27ac\", \"H3K36me3\", \"H3K27me3\", \"meth\"]:\n",
    "    loci = datatype_loci[dt]\n",
    "    loci.append(\"random1000x10000\")\n",
    "    loci.append(\"hg19_100000\")\n",
    "    if dt.startswith(\"H\"):\n",
    "        loci.append(\"coding_tss[-2000..2000]\")\n",
    "        loci.append(\"{}_zinbra_median_consensus\".format(dt))\n",
    "        loci.append(\"{}_zinbra_weak_consensus\".format(dt))\n",
    "        \n",
    "signals_root = Path(\"/mnt/stripe/bio/experiments/signal_experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:53.629127Z",
     "start_time": "2018-02-12T14:12:22.282217Z"
    }
   },
   "outputs": [],
   "source": [
    "folders = []\n",
    "for dt, loci in datatype_loci.items():\n",
    "    dt_root = signals_root / dt\n",
    "    if dt_root.exists():\n",
    "        folders.extend(f for f in walk_folders(dt_root) if f.name in loci)\n",
    "        \n",
    "paths = [p for folder in folders for p in collect_paths(folder)]\n",
    "print(\"Paths: \", len(paths))\n",
    "print(\"Loci folders: {}\".format(len(folders)), *[str(p) for p in folders], sep=\"\\n  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:53.654338Z",
     "start_time": "2018-02-12T14:12:53.647953Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = signals_root / \"validate.norms.permutation_r2.{}.csv\".format(simulations)\n",
    "output_path\n",
    "\n",
    "print(str(output_path), \"[exists]\" if output_path.exists() else \"[not exists]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:53.675912Z",
     "start_time": "2018-02-12T14:12:53.673086Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: clear paths? if clear cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:12:53.699632Z",
     "start_time": "2018-02-12T14:12:53.692695Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if clear_cache or not output_path.exists():\n",
    "    process(paths, str(output_path), seed=100, simulations=simulations, threads=threads)\n",
    "\n",
    "print(\"Results file: \", str(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:13:40.976318Z",
     "start_time": "2018-02-12T14:13:40.912247Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(output_path, index_col=None)\n",
    "df[\"loci\"] = [Path(f).name for f in df[\"file\"]]\n",
    "print(\"Shape:\", df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Avg and Sd bars for Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:26:29.597032Z",
     "start_time": "2018-02-12T16:26:26.105Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_summary_avg_sd_bars(df, metric):\n",
    "    plt.figure(figsize=(14, 6))\n",
    "    g = sns.barplot(data=df, y=metric, x=\"normalization\",\n",
    "                    hue=\"modification\", #order=sorted(datatype_loci.keys()),\n",
    "                    ci=\"sd\", capsize=.2, errwidth=1, # error bars\n",
    "                    #color=\"lightgray\", \n",
    "                    alpha=0.7,\n",
    "                    edgecolor=\"black\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    g.set_yscale('log')\n",
    "    plt.xticks(rotation=-90)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:15:43.893201Z",
     "start_time": "2018-02-12T14:15:43.029959Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_avg_sd_bars(df, \"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:15:44.878329Z",
     "start_time": "2018-02-12T14:15:43.936658Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_avg_sd_bars(df, \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:15:45.749426Z",
     "start_time": "2018-02-12T14:15:44.922438Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_avg_sd_bars(df, \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:15:46.762693Z",
     "start_time": "2018-02-12T14:15:45.795234Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_avg_sd_bars(df, \"wdist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Boxpots with Hist info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:27:23.121890Z",
     "start_time": "2018-02-12T16:27:23.114723Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_summary_boxplot_with_dtype(df, metric):\n",
    "    plt.figure(figsize=(16, 10))\n",
    "    ax = sns.boxplot(data=df, y=metric, hue=\"modification\", x=\"normalization\")\n",
    "    plt.xticks(rotation=-90)\n",
    "    plt.title(\"Signal R2 at selected loci\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:38:29.664567Z",
     "start_time": "2018-02-12T14:38:28.122325Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot_with_dtype(\"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:38:31.520182Z",
     "start_time": "2018-02-12T14:38:29.709556Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot_with_dtype(df, \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:38:33.283088Z",
     "start_time": "2018-02-12T14:38:31.563696Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot_with_dtype(df, \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T14:38:34.901072Z",
     "start_time": "2018-02-12T14:38:33.328204Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot_with_dtype(df, \"wdist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Boxpots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:27:17.698777Z",
     "start_time": "2018-02-12T16:27:17.692165Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_summary_boxplot(df, metric):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    ax = sns.boxplot(data=df[df.modification != \"meth\"], \n",
    "                     y=metric, x=\"normalization\")\n",
    "    plt.xticks(rotation=-90)\n",
    "    plt.title(\"Signal R2 at selected loci\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:22:05.137294Z",
     "start_time": "2018-02-12T16:22:04.416135Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot(df, \"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:22:05.541779Z",
     "start_time": "2018-02-12T16:22:05.181124Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot(df, \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:22:05.950297Z",
     "start_time": "2018-02-12T16:22:05.587611Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot(df, \"median\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:22:07.015242Z",
     "start_time": "2018-02-12T16:22:06.679271Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_summary_boxplot(df, \"wdist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boxpots by Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:27:28.535157Z",
     "start_time": "2018-02-12T16:27:28.515067Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_boxplot_by_norm(df, metric, ylim):\n",
    "    norms = sorted(set(df[\"normalization\"]))\n",
    "    n_subplots = math.ceil(np.sqrt(len(norms)))\n",
    "\n",
    "    plt.figure(figsize=(n_subplots*5, n_subplots*5))\n",
    "    \n",
    "    for i, norm in enumerate(norms, 1):\n",
    "        ax = plt.subplot(n_subplots, n_subplots, i)\n",
    "        g = sns.boxplot(data=df[df[\"normalization\"] == norm], y=metric, x=\"modification\",\n",
    "                        ax=ax)\n",
    "        for item in g.get_xticklabels():\n",
    "            item.set_rotation(-90)\n",
    "        ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        ax.set_title(norm)\n",
    "        ax.set_ylim(ylim)\n",
    "        \n",
    "    plt.subplots_adjust(top=0.92, bottom=0.08, left=0.10, right=0.95, hspace=0.35, wspace=0.35)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:25:01.697584Z",
     "start_time": "2018-02-12T16:24:59.628253Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_boxplot_by_norm(df, \"p2\", (0.7, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:25:03.772169Z",
     "start_time": "2018-02-12T16:25:01.742315Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_boxplot_by_norm(df, \"mean\", (0.9, 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:25:05.971505Z",
     "start_time": "2018-02-12T16:25:03.817145Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_boxplot_by_norm(df, \"wdist\", (0, 0.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed by Locus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:26:14.995072Z",
     "start_time": "2018-02-12T16:26:14.983634Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_detailed_by_locus(df, metric):\n",
    "    norms = sorted(set(df[\"normalization\"]))\n",
    "\n",
    "    for norm in norms:\n",
    "        plt.figure(figsize=(10,6))\n",
    "        g = sns.barplot(data=df[df[\"normalization\"] == norm], y=metric, x=\"loci\", hue=\"modification\")\n",
    "        for item in g.get_xticklabels():\n",
    "            item.set_rotation(-90)\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "        #plt.yscale(\"log\")\n",
    "        plt.title(norm)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:26:29.143777Z",
     "start_time": "2018-02-12T16:26:16.445971Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_detailed_by_locus(df, \"p2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T09:25:45.553684Z",
     "start_time": "2018-02-13T09:25:32.317801Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_detailed_by_locus(df, \"mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-12T16:26:29.593619Z",
     "start_time": "2018-02-12T16:26:16.923Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_detailed_by_locus(df, \"wdist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: So: \"rawq\", \"fripz\" or \"fripm\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalizations Correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:27:05.650996Z",
     "start_time": "2018-02-13T11:27:04.790680Z"
    },
    "code_folding": [
     97
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import math\n",
    "from itertools import chain\n",
    "\n",
    "HIST_MODS = [\"H3K4me1\", \"H3K4me3\", \"H3K27ac\", \"H3K27me3\", \"H3K36me3\"]\n",
    "def sorter_by_hist_and_donor(hist_ordering):\n",
    "    def inner(label):\n",
    "        # support both Y20O20 and ENCODE naming:\n",
    "        # * \"CD14_GSM1003562_Broad_r0_H3K36me3\"\n",
    "        # * \"OD_OD11_H3K4me1\"\n",
    "\n",
    "        hist = hist_for(label)\n",
    "        donor = label.replace(\"OD_\", \"\").replace(\"YD_\", \"\").replace(\"_\" + hist, \"\")\n",
    "        if donor.startswith(\"OD\") or donor.startswith(\"YD\"):\n",
    "            age = donor[0:2]\n",
    "            idx = int(donor[2:])\n",
    "        else:\n",
    "            age = \"_ENCODE_\"\n",
    "            idx = donor\n",
    "        return (hist_ordering[hist], age, idx)\n",
    "    return inner\n",
    "\n",
    "def hist_for(label):\n",
    "    m = re.match(\"((.*_)|^)(H[0-9]+K[a-z0-9]+).*\", label, re.IGNORECASE)\n",
    "    return label if not m else m.groups()[2]\n",
    "\n",
    "def color_annotator_hist(label):\n",
    "    color = {'H3K4me1':'lightblue', 'H3K4me3':'red', 'H3K27ac':'black',\n",
    "             'H3K27me3':'green', 'H3K36me3':'lightgray'}[hist_for(label)]\n",
    "\n",
    "    return ((\"Histone\", color),)\n",
    "\n",
    "def encode_annotator(label):\n",
    "    color = \"mediumseagreen\" if label.startswith(\"OD\") or label.startswith(\"YD\") else \"black\"\n",
    "    return ((\"Dataset\", color),)\n",
    "\n",
    "def norms_for_loci(signals_root, loci):\n",
    "    folders = []\n",
    "\n",
    "    for dt in HIST_MODS:\n",
    "        dt_root = signals_root / dt\n",
    "        if dt_root.exists():\n",
    "            folders.extend(f for f in walk_folders(dt_root) if f.name == loci)\n",
    "\n",
    "    paths = [p for folder in folders for p in collect_paths(folder)]\n",
    "    print(\"Paths: \", len(paths))\n",
    "    print(\"Loci folders: {}\".format(len(folders)), *[str(p) for p in folders], sep=\"\\n  \")\n",
    "\n",
    "    norm_2_paths = defaultdict(dict)\n",
    "    for p in paths:\n",
    "        dt = extract_datatype(p)\n",
    "        norm = extract_normalization(p)\n",
    "        norm_2_paths[norm][dt] = [p]\n",
    "        \n",
    "    return norm_2_paths\n",
    "\n",
    "def pearson_corr_df(norm, norm_2_paths, threads):\n",
    "    timeout_mins = 10\n",
    "    hist_mods = HIST_MODS\n",
    "\n",
    "    norm_paths = norm_2_paths[norm]\n",
    "    print(\"[{}]\".format(norm))\n",
    "    print(\"    Paths:\", *[str(p) for _h, p in norm_paths.items()], sep=\"\\n      \")\n",
    "    assert(set(norm_paths.keys()) == set(hist_mods))\n",
    "\n",
    "    print(\"    Load data...\".format(norm))\n",
    "    all_cols_names = []\n",
    "    all_cols = []\n",
    "    for dt, paths in norm_paths.items():\n",
    "        for path in paths:\n",
    "            df = pd.DataFrame.from_csv(path, sep=\"\\t\", index_col=None).drop([\"chr\", \"start\", \"end\"], axis=1)\n",
    "            fcols = [c for c in df.columns if \"input\" not in c.lower()]\n",
    "            df = df.loc[:, fcols]\n",
    "            all_cols_names.extend(df.columns)\n",
    "            for i in range(0, len(df.columns)):\n",
    "                all_cols.append(df.iloc[:, i])\n",
    "\n",
    "    n = len(all_cols)\n",
    "    print(\"    Calculating pearson correlation\".format(norm))\n",
    "    \n",
    "    # calc pearson correlation in parallel, split caclulations in equally sized chunks\n",
    "    x = np.zeros((n, n), np.float32)\n",
    "    \n",
    "    if threads == 1:    \n",
    "        for i in range(0, n):\n",
    "            for j in range(i, n):\n",
    "                corr = pearsonr(all_cols[i], all_cols[j])[0]\n",
    "                x[i, j] = corr\n",
    "                x[j, i] = corr\n",
    "    else:\n",
    "        cols_pairs = [(i, j) for i in range(0, n) for j in range(i, n)]\n",
    "        chunk_size = max(1, math.ceil(len(cols_pairs) / threads))\n",
    "        \n",
    "        # Pool cannot pass big arrays to threads =(\n",
    "        with Pool(processes=threads) as pool:\n",
    "            multiple_results = [\n",
    "                pool.apply_async(pearsonr_list, (all_cols, cols_pairs[s:s+chunk_size])) \n",
    "                for s in range(0, len(cols_pairs), chunk_size)\n",
    "            ]\n",
    "\n",
    "            values = list(chain(*[res.get(timeout=60 * timeout_mins) for res in multiple_results]))\n",
    "            for value, (i, j) in values:\n",
    "                x[i, j] = value\n",
    "                x[j, i] = value\n",
    "\n",
    "    return pd.DataFrame(data=x, columns=all_cols_names, index=all_cols_names)\n",
    "    \n",
    "def pearsonr_list(cols, pairs):\n",
    "    return [(pearsonr(cols[i], cols[j])[0], (i, j)) for i,j in pairs]\n",
    "\n",
    "def pearson_corr(norm, loci, norm_2_paths, pdf, threads, data_path=None):\n",
    "    if data_path and data_path.exists():\n",
    "        df = pd.DataFrame.from_csv(data_path, index_col=0)\n",
    "    else:\n",
    "        df = pearson_corr_df(norm, norm_2_paths, threads)\n",
    "        if data_path:\n",
    "            df.to_csv(data_path)\n",
    "            print(\"Corr table saved to: {}\".format(data_path))\n",
    "    \n",
    "    # plot:\n",
    "    hist_mods = HIST_MODS\n",
    "    # sort cols: by (hist, age, donor id) where hist in order according to hist_mods.\n",
    "    sorted_cols = sorted(df.columns, key=sorter_by_hist_and_donor({h:i for i, h in enumerate(hist_mods)}))\n",
    "    df = df.loc[sorted_cols, sorted_cols]\n",
    "\n",
    "    if any(not c.startswith(\"OD\") and not c.startswith(\"YD\") for c in df.columns):\n",
    "        ann=bm.color_annotator_chain(color_annotator_hist, encode_annotator)\n",
    "    else:\n",
    "        ann=color_annotator_hist\n",
    "    g = bm.plot_metric_heatmap(\"{}: Pearson Correlation for {}\".format(norm, loci), df, show_or_save_plot=False, cbar=False,\n",
    "                               col_color_annotator=ann, \n",
    "                               row_color_annotator=ann)\n",
    "\n",
    "    hist_donors_cnt = Counter()\n",
    "    for label in df.columns:\n",
    "        hist = hist_for(label)\n",
    "        hist_donors_cnt[hist] += 1\n",
    "        \n",
    "    hist_donors_counts = [hist_donors_cnt[h] for h in hist_mods]\n",
    "\n",
    "    ticks = [sum(hist_donors_counts[0:k]) + hist_donors_counts[k]/2 for k in range(len(hist_donors_counts))]\n",
    "    g.ax_heatmap.set_xticks(ticks)\n",
    "    g.ax_heatmap.set_xticklabels(hist_mods, rotation=\"horizontal\", horizontalalignment = 'center')\n",
    "    g.ax_heatmap.set_yticks(ticks)\n",
    "    g.ax_heatmap.set_yticklabels(hist_mods, rotation=\"vertical\", verticalalignment = 'center')\n",
    "\n",
    "    plt.setp(g.ax_heatmap.get_yticklabels(), rotation=90)\n",
    "\n",
    "    # Turn off annotations\n",
    "    #g.ax_col_colors.set_yticks([])\n",
    "    g.ax_row_colors.set_xticks([])\n",
    "\n",
    "    #bm.save_plot(plot_path)\n",
    "    if pdf:\n",
    "        pdf.savefig()\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:35:11.806994Z",
     "start_time": "2018-02-13T11:35:11.790265Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "def process_pearson_corr(signals_root, loci, threads, prefix=\"pearson_\"):\n",
    "    norm_2_paths = norms_for_loci(signals_root, loci)\n",
    "    for norm in sorted(list(norm_2_paths.keys())):\n",
    "        try:\n",
    "            plot_path = signals_root / \"{}{}_{}.pdf\".format(prefix, loci, norm)\n",
    "            data_path = plot_path.with_suffix(\".csv\")\n",
    "            if clear_cache:\n",
    "                ! rm $data_path\n",
    "            \n",
    "            with PdfPages(str(plot_path)) as pdf:\n",
    "                pearson_corr(norm, loci, norm_2_paths, pdf, threads, data_path)\n",
    "            print(\"Saved: \", plot_path)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed:\", norm, e)\n",
    "            traceback.print_exc()\n",
    "            #raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y20O20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:12:24.355016Z",
     "start_time": "2018-02-13T11:11:46.835575Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_pearson_corr(Path(\"/mnt/stripe/bio/experiments/signal_experiment\"), \"hg19_100000\", \n",
    "                     threads, \"pearson_y20o20_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:13:04.016140Z",
     "start_time": "2018-02-13T11:12:24.517533Z"
    }
   },
   "outputs": [],
   "source": [
    "process_pearson_corr(Path(\"/mnt/stripe/bio/experiments/signal_experiment\"), \"hg19_1000\", \n",
    "                     1, \"pearson_y20o20_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:13:09.278926Z",
     "start_time": "2018-02-13T11:13:04.184217Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_pearson_corr(Path(\"/mnt/stripe/bio/experiments/signal_experiment_encode\"), \"hg19_100000\", \n",
    "                     threads, \"pearson_encode_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:13:14.360435Z",
     "start_time": "2018-02-13T11:13:09.447258Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "process_pearson_corr(Path(\"/mnt/stripe/bio/experiments/signal_experiment_encode\"), \"hg19_1000\", \n",
    "                     1, \"pearson_encode_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Y20O20 + Encode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:35:20.440263Z",
     "start_time": "2018-02-13T11:35:20.396863Z"
    }
   },
   "outputs": [],
   "source": [
    "import traceback\n",
    "def process_enc_aging_pearson_corr(loci, threads):\n",
    "    root = Path(\"/mnt/stripe/bio/experiments\")\n",
    "    encode_norm_2_paths = norms_for_loci(root / \"signal_experiment_encode\" , loci)\n",
    "    y20od20_norm_2_paths = norms_for_loci(root / \"signal_experiment\", loci)\n",
    "\n",
    "    for norm in sorted(list(y20od20_norm_2_paths.keys())):\n",
    "        if norm not in encode_norm_2_paths:\n",
    "            print(\"No {} for ENCODE\".format(norm))\n",
    "\n",
    "        if set(HIST_MODS) !=  set(y20od20_norm_2_paths[norm]):\n",
    "            print(\"[{}]: Y20O20 missed hist modes, available only {}\".format(\n",
    "                norm, sorted(list(y20od20_norm_2_paths[norm].keys()))\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        if set(HIST_MODS) !=  set(encode_norm_2_paths[norm]):\n",
    "            print(\"[{}]: ENCODE missed hist modes, available only {}\".format(\n",
    "                norm, sorted(list(encode_norm_2_paths[norm].keys()))\n",
    "            ))\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            plot_path = root / \"signal_experiment/pearson_enc_vs_y20o20_{}_{}.pdf\".format(loci, norm)\n",
    "            data_path = plot_path.with_suffix(\".csv\")\n",
    "            if clear_cache:\n",
    "                ! rm $data_path\n",
    "            \n",
    "            with PdfPages(str(plot_path)) as pdf:\n",
    "                pearson_corr(norm, loci, \n",
    "                             {norm: {h: y20od20_norm_2_paths[norm][h] + encode_norm_2_paths[norm][h] for h in HIST_MODS}},\n",
    "                             None, threads, data_path)\n",
    "            print(\"Saved: {}\".format(plot_path))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(\"Failed:\", norm, e)\n",
    "            traceback.print_exc()\n",
    "            #raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:19:30.128580Z",
     "start_time": "2018-02-13T11:17:49.551229Z"
    }
   },
   "outputs": [],
   "source": [
    "process_enc_aging_pearson_corr(\"hg19_100000\", threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-13T11:20:14.421112Z",
     "start_time": "2018-02-13T11:19:30.295560Z"
    }
   },
   "outputs": [],
   "source": [
    "process_enc_aging_pearson_corr(\"hg19_1000\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H3K27me3 + DiffBind scores options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T08:15:57.614607Z",
     "start_time": "2018-02-02T08:15:57.585502Z"
    }
   },
   "outputs": [],
   "source": [
    "signals_root = Path(\"/mnt/stripe/bio/experiments/k27me3@dmrs\")\n",
    "paths = [p for p in signals_root.glob(\"k*_counts.csv\")]\n",
    "[p.name for p in paths]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T08:16:02.813689Z",
     "start_time": "2018-02-02T08:16:02.807009Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path = signals_root / \"validate.norms.permutation_r2.{}.csv\".format(simulations)\n",
    "output_path\n",
    "\n",
    "print(str(output_path), \"[exists]\" if output_path.exists() else \"[not exists]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T09:06:32.273036Z",
     "start_time": "2018-02-02T08:16:09.094911Z"
    }
   },
   "outputs": [],
   "source": [
    "if not output_path.exists():\n",
    "    process(paths, str(output_path), seed=100, simulations=simulations, threads=threads)\n",
    "print(\"Results file: \", str(output_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-02-02T09:06:32.355344Z",
     "start_time": "2018-02-02T09:06:32.295529Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_csv(output_path, index_col=None)\n",
    "df[\"loci\"] = [Path(f).name for f in df[\"file\"]]\n",
    "print(\"Shape:\", df.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "719px",
    "left": "0px",
    "right": "1168px",
    "top": "107px",
    "width": "272px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
